{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll help refactor this code to improve its organization, maintainability, and separation of concerns. I'll focus on creating a more modular structure with better dependency management.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# config.py\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class AppConfig:\n",
    "    \"\"\"Application configuration using dataclass for immutability and type hints\"\"\"\n",
    "    base_dir: str = os.path.dirname(os.path.abspath(__file__))\n",
    "    transcribe_api_url: str = 'http://103.253.20.13:25029/role_assign'\n",
    "    analyze_api_url: str = 'http://localhost:25034/analyze'\n",
    "    secret_key: str = 'codedongian'\n",
    "    scopes: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.credentials_path = os.path.join(self.base_dir, 'credentials.json')\n",
    "        self.token_path = os.path.join(self.base_dir, 'token.pickle')\n",
    "        self.database_path = os.path.join(self.base_dir, 'video_database.db')\n",
    "        self.temp_dir = os.path.join(self.base_dir, 'temp_files')\n",
    "        self.log_dir = os.path.join(self.base_dir, 'logs')\n",
    "        self.scopes = [\n",
    "            'https://www.googleapis.com/auth/drive',\n",
    "            'https://www.googleapis.com/auth/drive.file',\n",
    "            'https://www.googleapis.com/auth/drive.readonly'\n",
    "        ]\n",
    "\n",
    "# database.py\n",
    "from contextlib import contextmanager\n",
    "import sqlite3\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "class Database:\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "        self._initialize_db()\n",
    "\n",
    "    @contextmanager\n",
    "    def get_connection(self):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        try:\n",
    "            yield conn\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "    def _initialize_db(self):\n",
    "        with self.get_connection() as conn:\n",
    "            conn.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS videos (\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    url_video TEXT NOT NULL UNIQUE,\n",
    "                    transcription TEXT,\n",
    "                    criteria TEXT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            ''')\n",
    "\n",
    "    def url_exists(self, url: str) -> bool:\n",
    "        with self.get_connection() as conn:\n",
    "            cursor = conn.execute('SELECT 1 FROM videos WHERE url_video = ?', (url,))\n",
    "            return cursor.fetchone() is not None\n",
    "\n",
    "    def insert_video(self, url: str, transcription: str, criteria: Optional[str] = None) -> bool:\n",
    "        try:\n",
    "            with self.get_connection() as conn:\n",
    "                conn.execute(\n",
    "                    'INSERT INTO videos (url_video, transcription, criteria) VALUES (?, ?, ?)',\n",
    "                    (url, transcription, criteria or 'Pending analysis')\n",
    "                )\n",
    "                return True\n",
    "        except sqlite3.IntegrityError:\n",
    "            return False\n",
    "\n",
    "# google_drive.py\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import pickle\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "class GoogleDriveService:\n",
    "    def __init__(self, config: AppConfig):\n",
    "        self.config = config\n",
    "        self.service = self._authenticate()\n",
    "\n",
    "    def _authenticate(self):\n",
    "        creds = None\n",
    "        if os.path.exists(self.config.token_path):\n",
    "            with open(self.config.token_path, 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    self.config.credentials_path, self.config.scopes)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            \n",
    "            with open(self.config.token_path, 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    def get_drive_id(self, folder_id: str) -> Optional[str]:\n",
    "        try:\n",
    "            file = self.service.files().get(\n",
    "                fileId=folder_id,\n",
    "                fields=\"driveId\",\n",
    "                supportsAllDrives=True\n",
    "            ).execute()\n",
    "            return file.get('driveId')\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def list_folder_contents(self, folder_id: str) -> List[dict]:\n",
    "        drive_id = self.get_drive_id(folder_id)\n",
    "        query = f\"'{folder_id}' in parents\"\n",
    "        \n",
    "        params = {\n",
    "            'q': query,\n",
    "            'fields': \"files(id, name, mimeType)\",\n",
    "            'supportsAllDrives': True,\n",
    "            'includeItemsFromAllDrives': True,\n",
    "            'pageSize': 100\n",
    "        }\n",
    "        \n",
    "        if drive_id:\n",
    "            params.update({\n",
    "                'corpora': 'drive',\n",
    "                'driveId': drive_id\n",
    "            })\n",
    "            \n",
    "        results = self.service.files().list(**params).execute()\n",
    "        return results.get('files', [])\n",
    "\n",
    "# audio_processor.py\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class AudioProcessor:\n",
    "    def __init__(self, config: AppConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def process_audio(self, audio_path: str, language: str = 'en') -> Optional[Dict]:\n",
    "        if not os.path.exists(audio_path):\n",
    "            return None\n",
    "\n",
    "        with open(audio_path, 'rb') as audio_file:\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    self.config.transcribe_api_url,\n",
    "                    files={'audio': audio_file},\n",
    "                    data={\n",
    "                        'secret_key': self.config.secret_key,\n",
    "                        'language': language\n",
    "                    }\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "    def analyze_transcript(self, transcript: str) -> Optional[str]:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.config.analyze_api_url,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                json={\"transcription\": transcript},\n",
    "                timeout=60\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if 'criteria' in result:\n",
    "                    return json.dumps(result['criteria'], ensure_ascii=False, indent=2)\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_transcriptions(hv_output: Dict, mentor_output: Dict) -> str:\n",
    "        def extract_dicts(s: str) -> List[Dict]:\n",
    "            pattern = r\"\\{[^{}]*\\}\"\n",
    "            matches = re.findall(pattern, s)\n",
    "            result = []\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    match = match.replace(\"'\", '\"')\n",
    "                    result.append(json.loads(match))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "            return result\n",
    "\n",
    "        def format_time(milliseconds: int) -> str:\n",
    "            seconds = milliseconds // 1000\n",
    "            hours, remainder = divmod(seconds, 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "        try:\n",
    "            hv_data = extract_dicts(hv_output['output'])\n",
    "            mentor_data = extract_dicts(mentor_output['output'])\n",
    "\n",
    "            formatted = []\n",
    "            for item in hv_data:\n",
    "                time = format_time(item['start_time'])\n",
    "                formatted.append(f\"[{time}] Mentee: {item['text']}\")\n",
    "            \n",
    "            for item in mentor_data:\n",
    "                time = format_time(item['start_time'])\n",
    "                formatted.append(f\"[{time}] Mentor: {item['text']}\")\n",
    "\n",
    "            formatted.sort(key=lambda x: x[1:9])\n",
    "            return '\\n'.join(formatted)\n",
    "\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "# video_processor.py\n",
    "import gdown\n",
    "import logging\n",
    "from typing import Optional, Tuple\n",
    "import time\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, config: AppConfig, logger: logging.Logger):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "        self.db = Database(config.database_path)\n",
    "        self.drive_service = GoogleDriveService(config)\n",
    "        self.audio_processor = AudioProcessor(config)\n",
    "\n",
    "    def find_folders(self, folder_id: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "        files = self.drive_service.list_folder_contents(folder_id)\n",
    "        \n",
    "        audio_folder = None\n",
    "        video_folder = None\n",
    "        \n",
    "        for item in files:\n",
    "            if item['mimeType'] == 'application/vnd.google-apps.folder':\n",
    "                name = item['name'].lower()\n",
    "                if 'audio' in name:\n",
    "                    audio_folder = item['id']\n",
    "                elif 'video' in name:\n",
    "                    video_folder = item['id']\n",
    "        \n",
    "        return audio_folder, video_folder\n",
    "\n",
    "    def process_video(self, video: dict, audio_files: List[dict]):\n",
    "        video_url = f\"https://drive.google.com/file/d/{video['id']}/view\"\n",
    "        \n",
    "        if self.db.url_exists(video_url):\n",
    "            self.logger.info(f\"Skipping existing video: {video['name']}\")\n",
    "            return\n",
    "\n",
    "        base_name = os.path.splitext(video['name'])[0]\n",
    "        matching_audio = [f for f in audio_files if base_name in f['name']]\n",
    "        \n",
    "        hv_file = next((f for f in matching_audio if 'HV' in f['name']), None)\n",
    "        mentor_file = next((f for f in matching_audio if 'mentor' in f['name']), None)\n",
    "\n",
    "        if not (hv_file and mentor_file):\n",
    "            self.logger.error(f\"Missing audio files for video: {video['name']}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Process HV file\n",
    "            hv_path = os.path.join(self.config.temp_dir, f\"hv_{video['id']}.wav\")\n",
    "            gdown.download(\n",
    "                f\"https://drive.google.com/uc?id={hv_file['id']}\", \n",
    "                hv_path, \n",
    "                quiet=True\n",
    "            )\n",
    "            hv_result = self.audio_processor.process_audio(hv_path)\n",
    "\n",
    "            # Process mentor file\n",
    "            mentor_path = os.path.join(self.config.temp_dir, f\"mentor_{video['id']}.wav\")\n",
    "            gdown.download(\n",
    "                f\"https://drive.google.com/uc?id={mentor_file['id']}\", \n",
    "                mentor_path, \n",
    "                quiet=True\n",
    "            )\n",
    "            mentor_result = self.audio_processor.process_audio(mentor_path)\n",
    "\n",
    "            if hv_result and mentor_result:\n",
    "                transcript = self.audio_processor.combine_transcriptions(hv_result, mentor_result)\n",
    "                criteria = self.audio_processor.analyze_transcript(transcript)\n",
    "                self.db.insert_video(video_url, transcript, criteria)\n",
    "\n",
    "            # Cleanup\n",
    "            for path in [hv_path, mentor_path]:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing video {video['name']}: {str(e)}\")\n",
    "\n",
    "    def process_folder(self, folder_id: str):\n",
    "        try:\n",
    "            drive_id = self.drive_service.get_drive_id(folder_id)\n",
    "            if not drive_id:\n",
    "                raise ValueError(\"Could not get Drive ID\")\n",
    "\n",
    "            audio_folder, video_folder = self.find_folders(folder_id)\n",
    "            if not (audio_folder and video_folder):\n",
    "                raise ValueError(\"Could not find both Audio and Video folders\")\n",
    "\n",
    "            videos = self.drive_service.list_folder_contents(video_folder)\n",
    "            audio_files = self.drive_service.list_folder_contents(audio_folder)\n",
    "\n",
    "            for video in videos:\n",
    "                self.process_video(video, audio_files)\n",
    "                time.sleep(3)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in folder processing: {str(e)}\")\n",
    "\n",
    "# main.py\n",
    "def setup_logging(config: AppConfig) -> logging.Logger:\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    if not logger.handlers:\n",
    "        os.makedirs(config.log_dir, exist_ok=True)\n",
    "        \n",
    "        file_handler = logging.FileHandler(\n",
    "            os.path.join(config.log_dir, 'app.log'),\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        file_handler.setFormatter(\n",
    "            logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        )\n",
    "        logger.addHandler(file_handler)\n",
    "        \n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setFormatter(\n",
    "            logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        )\n",
    "        logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def main():\n",
    "    config = AppConfig()\n",
    "    logger = setup_logging(config)\n",
    "    \n",
    "    try:\n",
    "        processor = VideoProcessor(config, logger)\n",
    "        folder_id = \"15ik6vWdz1IcbPmsPfr4p-DdszkB484yg\"\n",
    "        processor.process_folder(folder_id)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution error: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "```\n",
    "\n",
    "Key improvements in the refactored code:\n",
    "\n",
    "1. **Modular Structure**: Split the code into logical modules (config.py, database.py, google_drive.py, etc.)\n",
    "\n",
    "2. **Better Configuration Management**:\n",
    "   - Used dataclass for configuration\n",
    "   - Made configuration immutable\n",
    "   - Added type hints\n",
    "\n",
    "3. **Improved Database Handling**:\n",
    "   - Added connection context manager\n",
    "   - Better error handling\n",
    "   - Cleaner SQL operations\n",
    "\n",
    "4. **Enhanced Google Drive Integration**:\n",
    "   - Separated Google Drive operations\n",
    "   - Better authentication flow\n",
    "   - Cleaner API interactions\n",
    "\n",
    "5. **Better Audio Processing**:\n",
    "   - Separated audio processing logic\n",
    "   - Improved error handling\n",
    "   - Cleaner transcription combining\n",
    "\n",
    "6. **Improved Error Handling**:\n",
    "   - More specific error catching\n",
    "   - Better error logging\n",
    "   - Graceful failure handling\n",
    "\n",
    "7. **Type Hints**:\n",
    "   - Added throughout the codebase\n",
    "   - Improved code readability\n",
    "   - Better IDE support\n",
    "\n",
    "8. **Cleaner Code Organization**:\n",
    "   - Smaller, more focused classes\n",
    "   - Better separation of concerns\n",
    "   - More maintainable structure\n",
    "\n",
    "9. **Improved Logging**:\n",
    "   - Centralized logging setup\n",
    "   - Better log formatting\n",
    "   - More consistent logging\n",
    "\n",
    "10. **Better Resource Management**:\n",
    "    - Proper file cleanup\n",
    "    - Better connection handling\n",
    "    - Resource cleanup in error cases\n",
    "\n",
    "Would you like me to explain any particular part of the refactored code in more detail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config.py\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class AppConfig:\n",
    "    \"\"\"Application configuration using dataclass for immutability and type hints\"\"\"\n",
    "    base_dir: str = os.path.dirname(os.path.abspath(__file__))\n",
    "    transcribe_api_url: str = 'http://103.253.20.13:25029/role_assign'\n",
    "    analyze_api_url: str = 'http://localhost:25034/analyze'\n",
    "    secret_key: str = 'codedongian'\n",
    "    scopes: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.credentials_path = os.path.join(self.base_dir, 'credentials.json')\n",
    "        self.token_path = os.path.join(self.base_dir, 'token.pickle')\n",
    "        self.database_path = os.path.join(self.base_dir, 'video_database.db')\n",
    "        self.temp_dir = os.path.join(self.base_dir, 'temp_files')\n",
    "        self.log_dir = os.path.join(self.base_dir, 'logs')\n",
    "        self.scopes = [\n",
    "            'https://www.googleapis.com/auth/drive',\n",
    "            'https://www.googleapis.com/auth/drive.file',\n",
    "            'https://www.googleapis.com/auth/drive.readonly'\n",
    "        ]\n",
    "\n",
    "# database.py\n",
    "from contextlib import contextmanager\n",
    "import sqlite3\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "class Database:\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "        self._initialize_db()\n",
    "\n",
    "    @contextmanager\n",
    "    def get_connection(self):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        try:\n",
    "            yield conn\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "    def _initialize_db(self):\n",
    "        with self.get_connection() as conn:\n",
    "            conn.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS videos (\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    url_video TEXT NOT NULL UNIQUE,\n",
    "                    transcription TEXT,\n",
    "                    criteria TEXT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            ''')\n",
    "\n",
    "    def url_exists(self, url: str) -> bool:\n",
    "        with self.get_connection() as conn:\n",
    "            cursor = conn.execute('SELECT 1 FROM videos WHERE url_video = ?', (url,))\n",
    "            return cursor.fetchone() is not None\n",
    "\n",
    "    def insert_video(self, url: str, transcription: str, criteria: Optional[str] = None) -> bool:\n",
    "        try:\n",
    "            with self.get_connection() as conn:\n",
    "                conn.execute(\n",
    "                    'INSERT INTO videos (url_video, transcription, criteria) VALUES (?, ?, ?)',\n",
    "                    (url, transcription, criteria or 'Pending analysis')\n",
    "                )\n",
    "                return True\n",
    "        except sqlite3.IntegrityError:\n",
    "            return False\n",
    "\n",
    "# google_drive.py\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import pickle\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "class GoogleDriveService:\n",
    "    def __init__(self, config: AppConfig):\n",
    "        self.config = config\n",
    "        self.service = self._authenticate()\n",
    "\n",
    "    def _authenticate(self):\n",
    "        creds = None\n",
    "        if os.path.exists(self.config.token_path):\n",
    "            with open(self.config.token_path, 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    self.config.credentials_path, self.config.scopes)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            \n",
    "            with open(self.config.token_path, 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    def get_drive_id(self, folder_id: str) -> Optional[str]:\n",
    "        try:\n",
    "            file = self.service.files().get(\n",
    "                fileId=folder_id,\n",
    "                fields=\"driveId\",\n",
    "                supportsAllDrives=True\n",
    "            ).execute()\n",
    "            return file.get('driveId')\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def list_folder_contents(self, folder_id: str) -> List[dict]:\n",
    "        drive_id = self.get_drive_id(folder_id)\n",
    "        query = f\"'{folder_id}' in parents\"\n",
    "        \n",
    "        params = {\n",
    "            'q': query,\n",
    "            'fields': \"files(id, name, mimeType)\",\n",
    "            'supportsAllDrives': True,\n",
    "            'includeItemsFromAllDrives': True,\n",
    "            'pageSize': 100\n",
    "        }\n",
    "        \n",
    "        if drive_id:\n",
    "            params.update({\n",
    "                'corpora': 'drive',\n",
    "                'driveId': drive_id\n",
    "            })\n",
    "            \n",
    "        results = self.service.files().list(**params).execute()\n",
    "        return results.get('files', [])\n",
    "\n",
    "# audio_processor.py\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class AudioProcessor:\n",
    "    def __init__(self, config: AppConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def process_audio(self, audio_path: str, language: str = 'en') -> Optional[Dict]:\n",
    "        if not os.path.exists(audio_path):\n",
    "            return None\n",
    "\n",
    "        with open(audio_path, 'rb') as audio_file:\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    self.config.transcribe_api_url,\n",
    "                    files={'audio': audio_file},\n",
    "                    data={\n",
    "                        'secret_key': self.config.secret_key,\n",
    "                        'language': language\n",
    "                    }\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "    def analyze_transcript(self, transcript: str) -> Optional[str]:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.config.analyze_api_url,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                json={\"transcription\": transcript},\n",
    "                timeout=60\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                if 'criteria' in result:\n",
    "                    return json.dumps(result['criteria'], ensure_ascii=False, indent=2)\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_transcriptions(hv_output: Dict, mentor_output: Dict) -> str:\n",
    "        def extract_dicts(s: str) -> List[Dict]:\n",
    "            pattern = r\"\\{[^{}]*\\}\"\n",
    "            matches = re.findall(pattern, s)\n",
    "            result = []\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    match = match.replace(\"'\", '\"')\n",
    "                    result.append(json.loads(match))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "            return result\n",
    "\n",
    "        def format_time(milliseconds: int) -> str:\n",
    "            seconds = milliseconds // 1000\n",
    "            hours, remainder = divmod(seconds, 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "        try:\n",
    "            hv_data = extract_dicts(hv_output['output'])\n",
    "            mentor_data = extract_dicts(mentor_output['output'])\n",
    "\n",
    "            formatted = []\n",
    "            for item in hv_data:\n",
    "                time = format_time(item['start_time'])\n",
    "                formatted.append(f\"[{time}] Mentee: {item['text']}\")\n",
    "            \n",
    "            for item in mentor_data:\n",
    "                time = format_time(item['start_time'])\n",
    "                formatted.append(f\"[{time}] Mentor: {item['text']}\")\n",
    "\n",
    "            formatted.sort(key=lambda x: x[1:9])\n",
    "            return '\\n'.join(formatted)\n",
    "\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "# video_processor.py\n",
    "import gdown\n",
    "import logging\n",
    "from typing import Optional, Tuple\n",
    "import time\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, config: AppConfig, logger: logging.Logger):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "        self.db = Database(config.database_path)\n",
    "        self.drive_service = GoogleDriveService(config)\n",
    "        self.audio_processor = AudioProcessor(config)\n",
    "\n",
    "    def find_folders(self, folder_id: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "        files = self.drive_service.list_folder_contents(folder_id)\n",
    "        \n",
    "        audio_folder = None\n",
    "        video_folder = None\n",
    "        \n",
    "        for item in files:\n",
    "            if item['mimeType'] == 'application/vnd.google-apps.folder':\n",
    "                name = item['name'].lower()\n",
    "                if 'audio' in name:\n",
    "                    audio_folder = item['id']\n",
    "                elif 'video' in name:\n",
    "                    video_folder = item['id']\n",
    "        \n",
    "        return audio_folder, video_folder\n",
    "\n",
    "    def process_video(self, video: dict, audio_files: List[dict]):\n",
    "        video_url = f\"https://drive.google.com/file/d/{video['id']}/view\"\n",
    "        \n",
    "        if self.db.url_exists(video_url):\n",
    "            self.logger.info(f\"Skipping existing video: {video['name']}\")\n",
    "            return\n",
    "\n",
    "        base_name = os.path.splitext(video['name'])[0]\n",
    "        matching_audio = [f for f in audio_files if base_name in f['name']]\n",
    "        \n",
    "        hv_file = next((f for f in matching_audio if 'HV' in f['name']), None)\n",
    "        mentor_file = next((f for f in matching_audio if 'mentor' in f['name']), None)\n",
    "\n",
    "        if not (hv_file and mentor_file):\n",
    "            self.logger.error(f\"Missing audio files for video: {video['name']}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Process HV file\n",
    "            hv_path = os.path.join(self.config.temp_dir, f\"hv_{video['id']}.wav\")\n",
    "            gdown.download(\n",
    "                f\"https://drive.google.com/uc?id={hv_file['id']}\", \n",
    "                hv_path, \n",
    "                quiet=True\n",
    "            )\n",
    "            hv_result = self.audio_processor.process_audio(hv_path)\n",
    "\n",
    "            # Process mentor file\n",
    "            mentor_path = os.path.join(self.config.temp_dir, f\"mentor_{video['id']}.wav\")\n",
    "            gdown.download(\n",
    "                f\"https://drive.google.com/uc?id={mentor_file['id']}\", \n",
    "                mentor_path, \n",
    "                quiet=True\n",
    "            )\n",
    "            mentor_result = self.audio_processor.process_audio(mentor_path)\n",
    "\n",
    "            if hv_result and mentor_result:\n",
    "                transcript = self.audio_processor.combine_transcriptions(hv_result, mentor_result)\n",
    "                criteria = self.audio_processor.analyze_transcript(transcript)\n",
    "                self.db.insert_video(video_url, transcript, criteria)\n",
    "\n",
    "            # Cleanup\n",
    "            for path in [hv_path, mentor_path]:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing video {video['name']}: {str(e)}\")\n",
    "\n",
    "    def process_folder(self, folder_id: str):\n",
    "        try:\n",
    "            drive_id = self.drive_service.get_drive_id(folder_id)\n",
    "            if not drive_id:\n",
    "                raise ValueError(\"Could not get Drive ID\")\n",
    "\n",
    "            audio_folder, video_folder = self.find_folders(folder_id)\n",
    "            if not (audio_folder and video_folder):\n",
    "                raise ValueError(\"Could not find both Audio and Video folders\")\n",
    "\n",
    "            videos = self.drive_service.list_folder_contents(video_folder)\n",
    "            audio_files = self.drive_service.list_folder_contents(audio_folder)\n",
    "\n",
    "            for video in videos:\n",
    "                self.process_video(video, audio_files)\n",
    "                time.sleep(3)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in folder processing: {str(e)}\")\n",
    "\n",
    "# main.py\n",
    "def setup_logging(config: AppConfig) -> logging.Logger:\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    if not logger.handlers:\n",
    "        os.makedirs(config.log_dir, exist_ok=True)\n",
    "        \n",
    "        file_handler = logging.FileHandler(\n",
    "            os.path.join(config.log_dir, 'app.log'),\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        file_handler.setFormatter(\n",
    "            logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        )\n",
    "        logger.addHandler(file_handler)\n",
    "        \n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setFormatter(\n",
    "            logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        )\n",
    "        logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def main():\n",
    "    config = AppConfig()\n",
    "    logger = setup_logging(config)\n",
    "    \n",
    "    try:\n",
    "        processor = VideoProcessor(config, logger)\n",
    "        folder_id = \"15ik6vWdz1IcbPmsPfr4p-DdszkB484yg\"\n",
    "        processor.process_folder(folder_id)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution error: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
