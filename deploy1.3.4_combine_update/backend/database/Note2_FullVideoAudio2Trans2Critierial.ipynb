{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thay vì việc xài database của a Hoàng sau đó lại truy vấn từ database để mà lấy transcriptions làm input cho get Critierial \n",
    "\n",
    "=> thì thôi, làm 1 mạch luôn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy phân tích input và output của code này:\n",
    "\n",
    "**INPUT:**\n",
    "1. **Google Drive Folder ID:** \n",
    "```python\n",
    "google_drive_files(\"1_oVkhMaU4M1-ZIkb5sL4XSRE1LmZUn3z\")\n",
    "```\n",
    "- Đây là ID của một folder trên Google Drive\n",
    "- Folder này được mong đợi có cấu trúc:\n",
    "  - Một thư mục con \"Audio\" chứa các file âm thanh\n",
    "  - Một thư mục con \"Video\" chứa các file video\n",
    "\n",
    "2. **Credentials cho Google Drive API:**\n",
    "```python\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "```\n",
    "- Cần file `credentials.json` để xác thực với Google Drive API\n",
    "- Sẽ tạo `token.pickle` để lưu token xác thực\n",
    "\n",
    "3. **Audio Files:**\n",
    "- File âm thanh được xử lý qua API tại endpoint:\n",
    "```python\n",
    "url = 'http://103.253.20.13:25029/role_assign'\n",
    "```\n",
    "- Yêu cầu secret key: 'codedongian'\n",
    "- Yêu cầu parameter language (ví dụ: 'en' cho tiếng Anh)\n",
    "\n",
    "**OUTPUT:**\n",
    "\n",
    "1. **Cấu trúc thư mục local:**\n",
    "```\n",
    "audio_data/\n",
    "    ├── [folder_name]/\n",
    "    │   ├── Audio/         # Chứa file audio đã download\n",
    "    │   ├── Text/          # Chứa file text được xử lý từ audio\n",
    "    │   └── Transcript/    # Chứa transcript cuối cùng\n",
    "```\n",
    "\n",
    "2. **Database SQLite:**\n",
    "- File: `audio_data.db`\n",
    "- Cấu trúc bảng:\n",
    "```sql\n",
    "CREATE TABLE audio_data (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    file_name_video TEXT,\n",
    "    file_name_audio TEXT, \n",
    "    url_video TEXT,\n",
    "    url_audio TEXT,\n",
    "    transcript TEXT\n",
    ")\n",
    "```\n",
    "\n",
    "3. **Files được tạo ra:**\n",
    "- Các file audio được download từ Google Drive vào thư mục `Audio/`\n",
    "- File text chứa kết quả xử lý audio (`.txt`) trong thư mục `Text/`\n",
    "  - Gồm 2 loại: `HV.txt` và `mentor.txt`\n",
    "- File transcript cuối cùng trong thư mục `Transcript/`\n",
    "  - Được tạo từ việc kết hợp `HV.txt` và `mentor.txt`\n",
    "  - Format: `[thời gian] Speaker 1/2: nội dung`\n",
    "\n",
    "**Quy trình xử lý:**\n",
    "\n",
    "1. Download files từ Google Drive:\n",
    "```python\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "gdown.download(url, local_path, quiet=False)\n",
    "```\n",
    "\n",
    "2. Xử lý audio thành text:\n",
    "```python\n",
    "output = process_audio(local_audio_file_path, 'en')\n",
    "```\n",
    "\n",
    "3. Kết hợp transcript từ 2 speakers:\n",
    "```python\n",
    "output = process_audio_outputs(output1, output2, new_filename)\n",
    "```\n",
    "\n",
    "4. Lưu thông tin vào database:\n",
    "```python\n",
    "insert_data(file_name_video, file_name_audio, url_video, url_audio, transcript, id)\n",
    "```\n",
    "\n",
    "5. Hiển thị dữ liệu đã xử lý:\n",
    "```python\n",
    "fetch_data(max_chars=10)  # Hiển thị preview của transcript với max 10 ký tự\n",
    "```\n",
    "\n",
    "**Ví dụ output hiển thị:**\n",
    "```\n",
    "ID: 1, FILE NAME VIDEO: video1.mp4, FILE NAME AUDIO: audio1.wav, \n",
    "URL VIDEO: https://drive.../view, URL AUDIO: https://drive.../view, \n",
    "TRANSCRIPT: [00:00:15] Speaker 1: Hello...\n",
    "```\n",
    "\n",
    "Đây là một pipeline xử lý audio hoàn chỉnh từ:\n",
    "1. Download file từ Google Drive\n",
    "2. Xử lý audio thành text \n",
    "3. Kết hợp transcript từ nhiều speakers\n",
    "4. Lưu trữ vào database\n",
    "5. Tổ chức file một cách có hệ thống\n",
    "\n",
    "Bạn cần quan tâm nhất đến:\n",
    "1. Folder ID input phải đúng cấu trúc\n",
    "2. Cần có credentials cho Google Drive API\n",
    "3. API xử lý audio phải hoạt động\n",
    "4. Database SQLite phải có quyền write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bỏ phần lưu output ở local, chỉ cần phần database, gồm có 2 trường thông tin:\n",
    "\n",
    "1. URL_video (dạng như full này: https://drive.google.com/file/d/10qe6DkNX6up7-oG69HRG3B4j1A-WiI_o/view) \n",
    "\n",
    "Transcriptions \n",
    "\n",
    "Criteria:    là output khi       cho transcriptions cho qua API sau \n",
    "\n",
    "curl --location 'http://103.253.20.13:25034/analyze' \\\n",
    "\n",
    "--header 'Content-Type: application/json' \\\n",
    "\n",
    "--data '{\"transcription\": \"[00:04:15] Mentee: Oh, good afternoon.\\n[00:04:32] Mentor: Hello.\\n[00:04:35] Mentor: Good afternoon.\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, để tôi giải thích rõ hơn:\n",
    "\n",
    "1. **Về lưu tạm thời và xóa:**\n",
    "Trong code hiện tại, file được xóa ngay sau khi xử lý xong (trong hàm `download_and_process_video`). Điều này có thể gây ra vấn đề nếu có lỗi xảy ra trong quá trình xử lý.\n",
    "\n",
    "2. **Về database:**\n",
    "Hiện tại chỉ lưu URL video và criteria, chưa lưu transcription.\n",
    "\n",
    "Đây là phiên bản cải tiến:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, Tuple\n",
    "import requests\n",
    "import gdown\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import sqlite3\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration settings\"\"\"\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "    TRANSCRIBE_API_URL = 'http://103.253.20.13:25029/role_assign'\n",
    "    ANALYZE_API_URL = 'http://103.253.20.13:25034/analyze'\n",
    "    DATABASE_PATH = 'videos.db'\n",
    "    CREDENTIALS_PATH = 'credentials.json'\n",
    "    TOKEN_PATH = 'token.pickle'\n",
    "    SECRET_KEY = 'codedongian'\n",
    "    TEMP_DIR = 'temp_videos'\n",
    "    # Thời gian giữ file tạm (24 giờ)\n",
    "    TEMP_FILE_TTL = timedelta(hours=24)\n",
    "\n",
    "class DatabaseManager:\n",
    "    \"\"\"Handle database operations\"\"\"\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.create_database()\n",
    "\n",
    "    def create_database(self):\n",
    "        \"\"\"Create database with required table\"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            conn.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS videos (\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    url_video TEXT NOT NULL,\n",
    "                    transcription TEXT,\n",
    "                    criteria TEXT,\n",
    "                    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            ''')\n",
    "\n",
    "    def insert_video(self, url_video: str, transcription: str, criteria: str) -> bool:\n",
    "        \"\"\"Insert video data with timestamp\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                conn.execute('''\n",
    "                    INSERT INTO videos (url_video, transcription, criteria, processed_at)\n",
    "                    VALUES (?, ?, ?, CURRENT_TIMESTAMP)\n",
    "                ''', (url_video, transcription, criteria))\n",
    "                return True\n",
    "        except sqlite3.Error as e:\n",
    "            logger.error(f\"Database error: {e}\")\n",
    "            return False\n",
    "\n",
    "class TempFileManager:\n",
    "    \"\"\"Manage temporary files\"\"\"\n",
    "    def __init__(self, temp_dir: str, ttl: timedelta):\n",
    "        self.temp_dir = temp_dir\n",
    "        self.ttl = ttl\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    def cleanup_old_files(self):\n",
    "        \"\"\"Remove files older than TTL\"\"\"\n",
    "        now = datetime.now()\n",
    "        for filename in os.listdir(self.temp_dir):\n",
    "            filepath = os.path.join(self.temp_dir, filename)\n",
    "            file_modified = datetime.fromtimestamp(os.path.getmtime(filepath))\n",
    "            if now - file_modified > self.ttl:\n",
    "                try:\n",
    "                    os.remove(filepath)\n",
    "                    logger.info(f\"Removed old temp file: {filepath}\")\n",
    "                except OSError as e:\n",
    "                    logger.error(f\"Error removing temp file: {e}\")\n",
    "\n",
    "    def cleanup_all(self):\n",
    "        \"\"\"Remove all temporary files and directory\"\"\"\n",
    "        try:\n",
    "            shutil.rmtree(self.temp_dir)\n",
    "            logger.info(\"Cleaned up all temporary files\")\n",
    "        except OSError as e:\n",
    "            logger.error(f\"Error cleaning up temp files: {e}\")\n",
    "\n",
    "class TranscriptionProcessor:\n",
    "    \"\"\"Process audio transcription\"\"\"\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "    def process_audio(self, audio_path: str, language: str = 'en') -> Optional[Dict]:\n",
    "        \"\"\"Process audio file using the role_assign API\"\"\"\n",
    "        if not os.path.exists(audio_path):\n",
    "            logger.error(f\"Audio file not found: {audio_path}\")\n",
    "            return None\n",
    "\n",
    "        with open(audio_path, 'rb') as audio_file:\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    self.config.TRANSCRIBE_API_URL,\n",
    "                    files={'audio': audio_file},\n",
    "                    data={\n",
    "                        'secret_key': self.config.SECRET_KEY,\n",
    "                        'language': language\n",
    "                    }\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logger.error(f\"Transcription API error: {e}\")\n",
    "                return None\n",
    "            except json.JSONDecodeError as e:\n",
    "                logger.error(f\"JSON decode error: {e}\")\n",
    "                return None\n",
    "\n",
    "    def analyze_transcript(self, transcript: str) -> Optional[str]:\n",
    "        \"\"\"Send transcript to analysis API and get criteria\"\"\"\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.config.ANALYZE_API_URL,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                json={'transcription': transcript},\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('criteria', '')\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Analysis API error: {e}\")\n",
    "            return None\n",
    "\n",
    "class VideoProcessor:\n",
    "    \"\"\"Process videos from Google Drive\"\"\"\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.db = DatabaseManager(config.DATABASE_PATH)\n",
    "        self.temp_manager = TempFileManager(config.TEMP_DIR, config.TEMP_FILE_TTL)\n",
    "        self.transcription_processor = TranscriptionProcessor(config)\n",
    "        self.drive_service = self._authenticate_google_drive()\n",
    "\n",
    "    def _authenticate_google_drive(self):\n",
    "        \"\"\"Authenticate with Google Drive API\"\"\"\n",
    "        creds = None\n",
    "        if os.path.exists(self.config.TOKEN_PATH):\n",
    "            with open(self.config.TOKEN_PATH, 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    self.config.CREDENTIALS_PATH, self.config.SCOPES)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            \n",
    "            with open(self.config.TOKEN_PATH, 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    def download_and_process_video(self, video_id: str, video_name: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "        \"\"\"Download video and process its audio\"\"\"\n",
    "        video_path = os.path.join(self.config.TEMP_DIR, video_name)\n",
    "        \n",
    "        try:\n",
    "            # Download video\n",
    "            download_url = f'https://drive.google.com/uc?id={video_id}'\n",
    "            gdown.download(download_url, video_path, quiet=False)\n",
    "            \n",
    "            # Process audio\n",
    "            transcription_result = self.transcription_processor.process_audio(video_path)\n",
    "            \n",
    "            if transcription_result:\n",
    "                transcription = transcription_result.get('output', '')\n",
    "                # Get criteria\n",
    "                criteria = self.transcription_processor.analyze_transcript(transcription)\n",
    "                return transcription, criteria\n",
    "                \n",
    "            return None, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing video: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def process_folder(self, folder_id: str):\n",
    "        \"\"\"Process videos in Google Drive folder\"\"\"\n",
    "        try:\n",
    "            # Cleanup old temporary files first\n",
    "            self.temp_manager.cleanup_old_files()\n",
    "\n",
    "            # Query for video files in the folder\n",
    "            query = f\"'{folder_id}' in parents\"\n",
    "            results = self.drive_service.files().list(\n",
    "                q=query,\n",
    "                fields=\"files(id, name)\"\n",
    "            ).execute()\n",
    "\n",
    "            videos = results.get('files', [])\n",
    "            \n",
    "            for video in videos:\n",
    "                # Generate video URL\n",
    "                video_url = f\"https://drive.google.com/file/d/{video['id']}/view\"\n",
    "                \n",
    "                # Process video\n",
    "                transcription, criteria = self.download_and_process_video(video['id'], video['name'])\n",
    "                \n",
    "                if transcription and criteria:\n",
    "                    # Save to database\n",
    "                    self.db.insert_video(video_url, transcription, criteria)\n",
    "                    logger.info(f\"Processed video: {video['name']}\")\n",
    "                else:\n",
    "                    logger.error(f\"Failed to process video: {video['name']}\")\n",
    "\n",
    "                # Sleep to avoid rate limiting\n",
    "                time.sleep(3)\n",
    "\n",
    "            # Cleanup all temporary files after processing\n",
    "            self.temp_manager.cleanup_all()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing folder: {e}\")\n",
    "            # Ensure cleanup happens even if there's an error\n",
    "            self.temp_manager.cleanup_all()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    config = Config()\n",
    "    processor = VideoProcessor(config)\n",
    "    \n",
    "    try:\n",
    "        # Process folder\n",
    "        folder_id = \"1_oVkhMaU4M1-ZIkb5sL4XSRE1LmZUn3z\"  # Your folder ID\n",
    "        processor.process_folder(folder_id)\n",
    "        \n",
    "        # Display results\n",
    "        with sqlite3.connect(config.DATABASE_PATH) as conn:\n",
    "            cursor = conn.execute('SELECT id, url_video, criteria, processed_at FROM videos')\n",
    "            for row in cursor.fetchall():\n",
    "                print(f\"\\nVideo ID: {row[0]}\")\n",
    "                print(f\"URL: {row[1]}\")\n",
    "                print(f\"Criteria: {row[2]}\")\n",
    "                print(f\"Processed at: {row[3]}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main execution error: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "```\n",
    "\n",
    "Những cải tiến chính:\n",
    "\n",
    "1. **Quản lý file tạm tốt hơn:**\n",
    "```python\n",
    "class TempFileManager:\n",
    "    # File tạm được giữ trong 24h \n",
    "    TEMP_FILE_TTL = timedelta(hours=24)\n",
    "    \n",
    "    def cleanup_old_files(self):\n",
    "        # Xóa file cũ hơn 24h\n",
    "    \n",
    "    def cleanup_all(self):\n",
    "        # Xóa tất cả file tạm sau khi xử lý xong\n",
    "```\n",
    "\n",
    "2. **Database schema mới:**\n",
    "```sql\n",
    "CREATE TABLE videos (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    url_video TEXT NOT NULL,\n",
    "    transcription TEXT,        -- Thêm trường này\n",
    "    criteria TEXT,\n",
    "    processed_at TIMESTAMP     -- Thêm timestamp\n",
    ")\n",
    "```\n",
    "\n",
    "3. **Quy trình xử lý:**\n",
    "- Trước khi xử lý: Dọn file tạm cũ (>24h)\n",
    "- Trong khi xử lý: Giữ file tạm để debug nếu cần\n",
    "- Sau khi xử lý xong folder: Xóa tất cả file tạm\n",
    "- Nếu có lỗi: Vẫn đảm bảo xóa file tạm\n",
    "\n",
    "4. **Logging và Error Handling tốt hơn:**\n",
    "- Log đầy đủ các bước xử lý\n",
    "- Catch và handle exceptions ở mỗi bước\n",
    "- Cleanup resources trong mọi trường hợp\n",
    "\n",
    "Bạn thấy phiên bản này có ổn không? Tôi có thể điều chỉnh thêm nếu cần."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Code này đang lưu những trường nào nhỉ, \n",
    "\n",
    "nên check URL video từ Google Drive trong database. \n",
    "\n",
    "Nếu có rồi thì bỏ qua\n",
    "\n",
    "Chưa có thì mới lấy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có phải bạn đang lấy URL_video từ Google Drive\n",
    "\n",
    "Từ URL_video, tiến hành tìm 2 file audio, sử dụng 2 audio đó để cho qua : # Transcribe API url = 'http://103.253.20.13:25029/role_assign'\n",
    "\n",
    "-> sau đó lấy: transcription\n",
    "\n",
    "Sau đó từ transcription -> lấy được criteria ...\n",
    "\n",
    "bằng cách cho qua # Analyze API url = 'http://103.253.20.13:25034/analyze'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Không đúng rồi. Code hiện tại đang làm sai quy trình. Hãy làm rõ quy trình đúng:\n",
    "\n",
    "1. **Input từ Google Drive:**\n",
    "- URL_video (dạng https://drive.google.com/file/d/{id}/view)\n",
    "- Từ URL này sẽ có 2 file audio liên quan\n",
    "\n",
    "2. **Quy trình xử lý:**\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[URL Video] --> B[Tìm 2 file audio liên quan]\n",
    "    B --> C[Process Audio 1 qua role_assign API]\n",
    "    B --> D[Process Audio 2 qua role_assign API]\n",
    "    C --> E[Combine transcriptions]\n",
    "    D --> E\n",
    "    E --> F[Send to analyze API]\n",
    "    F --> G[Get criteria]\n",
    "```\n",
    "\n",
    "Hãy sửa lại code cho đúng:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from typing import Optional, Dict, Tuple, List\n",
    "import requests\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import sqlite3\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "    TRANSCRIBE_API_URL = 'http://103.253.20.13:25029/role_assign'\n",
    "    ANALYZE_API_URL = 'http://103.253.20.13:25034/analyze'\n",
    "    DATABASE_PATH = 'videos.db'\n",
    "    CREDENTIALS_PATH = 'credentials.json'\n",
    "    TOKEN_PATH = 'token.pickle'\n",
    "    SECRET_KEY = 'codedongian'\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.create_database()\n",
    "\n",
    "    def create_database(self):\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            conn.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS videos (\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    url_video TEXT NOT NULL UNIQUE,\n",
    "                    transcription TEXT,\n",
    "                    criteria TEXT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            ''')\n",
    "\n",
    "    def url_exists(self, url_video: str) -> bool:\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.execute('SELECT COUNT(*) FROM videos WHERE url_video = ?', \n",
    "                                    (url_video,))\n",
    "                return cursor.fetchone()[0] > 0\n",
    "        except sqlite3.Error as e:\n",
    "            logger.error(f\"Database error checking URL: {e}\")\n",
    "            return False\n",
    "\n",
    "    def insert_video(self, url_video: str, transcription: str, criteria: str) -> bool:\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                conn.execute('''\n",
    "                    INSERT INTO videos (url_video, transcription, criteria)\n",
    "                    VALUES (?, ?, ?)\n",
    "                ''', (url_video, transcription, criteria))\n",
    "                return True\n",
    "        except sqlite3.IntegrityError:\n",
    "            logger.info(f\"Video URL already exists: {url_video}\")\n",
    "            return False\n",
    "        except sqlite3.Error as e:\n",
    "            logger.error(f\"Database error: {e}\")\n",
    "            return False\n",
    "\n",
    "class AudioProcessor:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "    def process_audio(self, audio_file_path: str, language: str = 'en') -> Optional[Dict]:\n",
    "        \"\"\"Process single audio file through role_assign API\"\"\"\n",
    "        if not os.path.exists(audio_file_path):\n",
    "            logger.error(f\"Audio file not found: {audio_file_path}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            with open(audio_file_path, 'rb') as audio:\n",
    "                response = requests.post(\n",
    "                    self.config.TRANSCRIBE_API_URL,\n",
    "                    files={'audio': audio},\n",
    "                    data={\n",
    "                        'secret_key': self.config.SECRET_KEY,\n",
    "                        'language': language\n",
    "                    }\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing audio: {e}\")\n",
    "            return None\n",
    "\n",
    "    def combine_transcriptions(self, transcription1: Dict, transcription2: Dict) -> str:\n",
    "        \"\"\"Combine transcriptions from two audio files\"\"\"\n",
    "        # Implement logic to combine transcriptions\n",
    "        # This should match your specific format requirements\n",
    "        combined = f\"{transcription1['output']}\\n{transcription2['output']}\"\n",
    "        return combined\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.db = DatabaseManager(config.DATABASE_PATH)\n",
    "        self.audio_processor = AudioProcessor(config)\n",
    "        self.drive_service = self._authenticate_google_drive()\n",
    "\n",
    "    def _authenticate_google_drive(self):\n",
    "        \"\"\"Authenticate with Google Drive API\"\"\"\n",
    "        creds = None\n",
    "        if os.path.exists(self.config.TOKEN_PATH):\n",
    "            with open(self.config.TOKEN_PATH, 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    self.config.CREDENTIALS_PATH, self.config.SCOPES)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            with open(self.config.TOKEN_PATH, 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    def find_related_audio_files(self, video_id: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "        \"\"\"Find the two related audio files for a video\"\"\"\n",
    "        try:\n",
    "            # Implement logic to find related audio files\n",
    "            # This should match your specific naming convention or relationship logic\n",
    "            file_list = self.drive_service.files().list(\n",
    "                q=f\"'{video_id}' in parents\",\n",
    "                fields=\"files(id, name)\"\n",
    "            ).execute()\n",
    "\n",
    "            audio_files = file_list.get('files', [])\n",
    "            if len(audio_files) >= 2:\n",
    "                return audio_files[0]['id'], audio_files[1]['id']\n",
    "            return None, None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error finding audio files: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def analyze_transcript(self, transcript: str) -> Optional[str]:\n",
    "        \"\"\"Get criteria from transcript using analyze API\"\"\"\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.config.ANALYZE_API_URL,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                json={'transcription': transcript},\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('criteria', '')\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_folder(self, folder_id: str):\n",
    "        \"\"\"Process videos in Google Drive folder\"\"\"\n",
    "        try:\n",
    "            query = f\"'{folder_id}' in parents\"\n",
    "            results = self.drive_service.files().list(\n",
    "                q=query,\n",
    "                fields=\"files(id, name)\"\n",
    "            ).execute()\n",
    "\n",
    "            videos = results.get('files', [])\n",
    "            \n",
    "            for video in videos:\n",
    "                video_url = f\"https://drive.google.com/file/d/{video['id']}/view\"\n",
    "                \n",
    "                if self.db.url_exists(video_url):\n",
    "                    logger.info(f\"Skipping existing video: {video['name']}\")\n",
    "                    continue\n",
    "\n",
    "                # Find related audio files\n",
    "                audio1_id, audio2_id = self.find_related_audio_files(video['id'])\n",
    "                if not audio1_id or not audio2_id:\n",
    "                    logger.error(f\"Could not find both audio files for video: {video['name']}\")\n",
    "                    continue\n",
    "\n",
    "                # Process both audio files\n",
    "                try:\n",
    "                    # Download audio files to temp directory\n",
    "                    os.makedirs('temp', exist_ok=True)\n",
    "                    audio1_path = os.path.join('temp', f'audio1_{video[\"id\"]}.wav')\n",
    "                    audio2_path = os.path.join('temp', f'audio2_{video[\"id\"]}.wav')\n",
    "                    \n",
    "                    # Process each audio file\n",
    "                    transcription1 = self.audio_processor.process_audio(audio1_path)\n",
    "                    transcription2 = self.audio_processor.process_audio(audio2_path)\n",
    "\n",
    "                    if transcription1 and transcription2:\n",
    "                        # Combine transcriptions\n",
    "                        combined_transcript = self.audio_processor.combine_transcriptions(\n",
    "                            transcription1, transcription2)\n",
    "                        \n",
    "                        # Get criteria\n",
    "                        criteria = self.analyze_transcript(combined_transcript)\n",
    "                        \n",
    "                        if criteria:\n",
    "                            # Save to database\n",
    "                            self.db.insert_video(video_url, combined_transcript, criteria)\n",
    "                            logger.info(f\"Successfully processed video: {video['name']}\")\n",
    "                        else:\n",
    "                            logger.error(f\"Failed to get criteria for video: {video['name']}\")\n",
    "                    \n",
    "                    # Cleanup\n",
    "                    os.remove(audio1_path)\n",
    "                    os.remove(audio2_path)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing audio files: {e}\")\n",
    "                    continue\n",
    "\n",
    "                time.sleep(3)  # Rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing folder: {e}\")\n",
    "\n",
    "def main():\n",
    "    config = Config()\n",
    "    processor = VideoProcessor(config)\n",
    "    \n",
    "    folder_id = \"1_oVkhMaU4M1-ZIkb5sL4XSRE1LmZUn3z\"\n",
    "    processor.process_folder(folder_id)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "```\n",
    "\n",
    "Những thay đổi chính:\n",
    "\n",
    "1. **Tách AudioProcessor riêng:**\n",
    "- Xử lý từng file audio\n",
    "- Combine transcriptions từ 2 file\n",
    "\n",
    "2. **Thêm find_related_audio_files:**\n",
    "```python\n",
    "def find_related_audio_files(self, video_id: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    # Tìm 2 file audio liên quan đến video\n",
    "```\n",
    "\n",
    "3. **Quy trình xử lý mới:**\n",
    "```python\n",
    "# 1. Lấy URL video\n",
    "video_url = f\"https://drive.google.com/file/d/{video['id']}/view\"\n",
    "\n",
    "# 2. Tìm 2 file audio liên quan\n",
    "audio1_id, audio2_id = self.find_related_audio_files(video['id'])\n",
    "\n",
    "# 3. Process từng file audio\n",
    "transcription1 = self.audio_processor.process_audio(audio1_path)\n",
    "transcription2 = self.audio_processor.process_audio(audio2_path)\n",
    "\n",
    "# 4. Combine transcriptions\n",
    "combined_transcript = self.audio_processor.combine_transcriptions(\n",
    "    transcription1, transcription2)\n",
    "\n",
    "# 5. Get criteria\n",
    "criteria = self.analyze_transcript(combined_transcript)\n",
    "```\n",
    "\n",
    "Bạn cần:\n",
    "1. Implement logic tìm 2 file audio liên quan trong `find_related_audio_files`\n",
    "2. Implement logic combine transcriptions trong `combine_transcriptions`\n",
    "theo đúng requirements của bạn.\n",
    "\n",
    "Đây là quy trình đúng chứ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tôi sẽ viết code kết hợp và giải thích chi tiết từng bước:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from typing import Optional, Dict, Tuple\n",
    "import requests\n",
    "import gdown\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration settings\"\"\"\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "    TRANSCRIBE_API_URL = 'http://103.253.20.13:25029/role_assign'\n",
    "    ANALYZE_API_URL = 'http://103.253.20.13:25034/analyze'\n",
    "    DATABASE_PATH = 'videos.db'\n",
    "    CREDENTIALS_PATH = 'credentials.json'\n",
    "    TOKEN_PATH = 'token.pickle'\n",
    "    SECRET_KEY = 'codedongian'\n",
    "    TEMP_DIR = 'temp_files'\n",
    "\n",
    "class DatabaseManager:\n",
    "    \"\"\"Handle database operations\"\"\"\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.create_database()\n",
    "\n",
    "    def create_database(self):\n",
    "        \"\"\"Create database with required table\"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            conn.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS videos (\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    url_video TEXT NOT NULL UNIQUE,\n",
    "                    transcription TEXT,\n",
    "                    criteria TEXT,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            ''')\n",
    "\n",
    "    def url_exists(self, url_video: str) -> bool:\n",
    "        \"\"\"Check if URL already exists in database\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.execute('SELECT COUNT(*) FROM videos WHERE url_video = ?', \n",
    "                                    (url_video,))\n",
    "                return cursor.fetchone()[0] > 0\n",
    "        except sqlite3.Error as e:\n",
    "            logger.error(f\"Database error checking URL: {e}\")\n",
    "            return False\n",
    "\n",
    "    def insert_video(self, url_video: str, transcription: str, criteria: str) -> bool:\n",
    "        \"\"\"Insert video data\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                conn.execute('''\n",
    "                    INSERT INTO videos (url_video, transcription, criteria)\n",
    "                    VALUES (?, ?, ?)\n",
    "                ''', (url_video, transcription, criteria))\n",
    "                return True\n",
    "        except sqlite3.IntegrityError:\n",
    "            logger.info(f\"Video URL already exists: {url_video}\")\n",
    "            return False\n",
    "        except sqlite3.Error as e:\n",
    "            logger.error(f\"Database error: {e}\")\n",
    "            return False\n",
    "\n",
    "class AudioProcessor:\n",
    "    \"\"\"Process audio files and transcriptions\"\"\"\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        os.makedirs(config.TEMP_DIR, exist_ok=True)\n",
    "\n",
    "    def extract_dicts(self, s: str) -> list:\n",
    "        \"\"\"Extract dictionaries from JSON string\"\"\"\n",
    "        pattern = r\"\\{[^{}]*\\}\"\n",
    "        matches = re.findall(pattern, s)\n",
    "        result = []\n",
    "        for match in matches:\n",
    "            try:\n",
    "                match = match.replace(\"'\", '\"')\n",
    "                d = json.loads(match)\n",
    "                result.append(d)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        return result\n",
    "\n",
    "    def format_time(self, milliseconds: int) -> str:\n",
    "        \"\"\"Format milliseconds to time string\"\"\"\n",
    "        seconds = milliseconds // 1000\n",
    "        minutes = seconds // 60\n",
    "        hours = minutes // 60\n",
    "        return f\"{hours:02d}:{minutes%60:02d}:{seconds%60:02d}\"\n",
    "\n",
    "    def process_audio(self, audio_path: str, language: str = 'en') -> Optional[Dict]:\n",
    "        \"\"\"Process single audio file through API\"\"\"\n",
    "        if not os.path.exists(audio_path):\n",
    "            logger.error(f\"Audio file not found: {audio_path}\")\n",
    "            return None\n",
    "\n",
    "        with open(audio_path, 'rb') as audio_file:\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    self.config.TRANSCRIBE_API_URL,\n",
    "                    files={'audio': audio_file},\n",
    "                    data={\n",
    "                        'secret_key': self.config.SECRET_KEY,\n",
    "                        'language': language\n",
    "                    }\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing audio: {e}\")\n",
    "                return None\n",
    "\n",
    "    def combine_transcriptions(self, hv_output: Dict, mentor_output: Dict) -> str:\n",
    "        \"\"\"Combine transcriptions from HV and mentor\"\"\"\n",
    "        try:\n",
    "            # Extract and format transcriptions\n",
    "            hv_data = self.extract_dicts(hv_output['output'])\n",
    "            mentor_data = self.extract_dicts(mentor_output['output'])\n",
    "\n",
    "            # Mark speakers\n",
    "            for item in hv_data:\n",
    "                item['speaker'] = '1'\n",
    "            for item in mentor_data:\n",
    "                item['speaker'] = '2'\n",
    "\n",
    "            # Combine and sort by time\n",
    "            combined = sorted(hv_data + mentor_data, key=lambda x: x['start_time'])\n",
    "\n",
    "            # Format output\n",
    "            formatted = []\n",
    "            for item in combined:\n",
    "                time = self.format_time(item['start_time'])\n",
    "                formatted.append(f\"[{time}] Speaker {item['speaker']}: {item['text']}\")\n",
    "\n",
    "            return \"\\n\".join(formatted)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error combining transcriptions: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def analyze_transcript(self, transcript: str) -> Optional[str]:\n",
    "        \"\"\"Get criteria from transcript\"\"\"\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.config.ANALYZE_API_URL,\n",
    "                headers={'Content-Type': 'application/json'},\n",
    "                json={'transcription': transcript},\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('criteria', '')\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "class VideoProcessor:\n",
    "    \"\"\"Main processor for handling videos and their related files\"\"\"\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.db = DatabaseManager(config.DATABASE_PATH)\n",
    "        self.audio_processor = AudioProcessor(config)\n",
    "        self.drive_service = self._authenticate_google_drive()\n",
    "\n",
    "    def _authenticate_google_drive(self):\n",
    "        \"\"\"Set up Google Drive authentication\"\"\"\n",
    "        creds = None\n",
    "        if os.path.exists(self.config.TOKEN_PATH):\n",
    "            with open(self.config.TOKEN_PATH, 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    self.config.CREDENTIALS_PATH, self.config.SCOPES)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            with open(self.config.TOKEN_PATH, 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    def find_folders(self, folder_id: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "        \"\"\"Find Audio and Video folders\"\"\"\n",
    "        query = f\"'{folder_id}' in parents and mimeType = 'application/vnd.google-apps.folder'\"\n",
    "        results = self.drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "        \n",
    "        audio_folder = None\n",
    "        video_folder = None\n",
    "        \n",
    "        for item in results.get('files', []):\n",
    "            if item['name'] == 'Audio':\n",
    "                audio_folder = item['id']\n",
    "            elif item['name'] == 'Video':\n",
    "                video_folder = item['id']\n",
    "        \n",
    "        return audio_folder, video_folder\n",
    "\n",
    "    def process_folder(self, folder_id: str):\n",
    "        \"\"\"Main processing function\"\"\"\n",
    "        try:\n",
    "            # 1. Find Audio and Video folders\n",
    "            audio_folder, video_folder = self.find_folders(folder_id)\n",
    "            if not audio_folder or not video_folder:\n",
    "                logger.error(\"Could not find both Audio and Video folders\")\n",
    "                return\n",
    "\n",
    "            # 2. Get videos\n",
    "            videos = self.drive_service.files().list(\n",
    "                q=f\"'{video_folder}' in parents\",\n",
    "                fields=\"files(id, name)\"\n",
    "            ).execute().get('files', [])\n",
    "\n",
    "            # 3. Process each video\n",
    "            for video in videos:\n",
    "                video_url = f\"https://drive.google.com/file/d/{video['id']}/view\"\n",
    "                \n",
    "                # Skip if already processed\n",
    "                if self.db.url_exists(video_url):\n",
    "                    logger.info(f\"Skipping existing video: {video['name']}\")\n",
    "                    continue\n",
    "\n",
    "                # 4. Find corresponding audio files\n",
    "                base_name = os.path.splitext(video['name'])[0]\n",
    "                audio_files = self.drive_service.files().list(\n",
    "                    q=f\"'{audio_folder}' in parents and (name contains '{base_name}')\",\n",
    "                    fields=\"files(id, name)\"\n",
    "                ).execute().get('files', [])\n",
    "\n",
    "                hv_file = None\n",
    "                mentor_file = None\n",
    "                for file in audio_files:\n",
    "                    if 'HV' in file['name']:\n",
    "                        hv_file = file\n",
    "                    elif 'mentor' in file['name']:\n",
    "                        mentor_file = file\n",
    "\n",
    "                if not (hv_file and mentor_file):\n",
    "                    logger.error(f\"Missing audio files for video: {video['name']}\")\n",
    "                    continue\n",
    "\n",
    "                # 5. Process audio files\n",
    "                try:\n",
    "                    # Download and process HV audio\n",
    "                    hv_path = os.path.join(self.config.TEMP_DIR, f\"hv_{video['id']}.wav\")\n",
    "                    gdown.download(f\"https://drive.google.com/uc?id={hv_file['id']}\", \n",
    "                                 hv_path, quiet=False)\n",
    "                    hv_result = self.audio_processor.process_audio(hv_path)\n",
    "\n",
    "                    # Download and process mentor audio\n",
    "                    mentor_path = os.path.join(self.config.TEMP_DIR, f\"mentor_{video['id']}.wav\")\n",
    "                    gdown.download(f\"https://drive.google.com/uc?id={mentor_file['id']}\", \n",
    "                                 mentor_path, quiet=False)\n",
    "                    mentor_result = self.audio_processor.process_audio(mentor_path)\n",
    "\n",
    "                    if hv_result and mentor_result:\n",
    "                        # 6. Combine transcriptions\n",
    "                        transcript = self.audio_processor.combine_transcriptions(\n",
    "                            hv_result, mentor_result)\n",
    "                        \n",
    "                        # 7. Get criteria\n",
    "                        criteria = self.audio_processor.analyze_transcript(transcript)\n",
    "                        \n",
    "                        if criteria:\n",
    "                            # 8. Save to database\n",
    "                            self.db.insert_video(video_url, transcript, criteria)\n",
    "                            logger.info(f\"Successfully processed video: {video['name']}\")\n",
    "\n",
    "                    # Cleanup temp files\n",
    "                    os.remove(hv_path)\n",
    "                    os.remove(mentor_path)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing files for video {video['name']}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                time.sleep(3)  # Rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in main processing: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    config = Config()\n",
    "    processor = VideoProcessor(config)\n",
    "    \n",
    "    folder_id = \"1_oVkhMaU4M1-ZIkb5sL4XSRE1LmZUn3z\"\n",
    "    processor.process_folder(folder_id)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "```\n",
    "\n",
    "**Quy trình xử lý:**\n",
    "\n",
    "1. **Setup và Cấu hình:**\n",
    "```python\n",
    "class Config:\n",
    "    # Lưu các thông số cấu hình: API URLs, paths, credentials\n",
    "```\n",
    "\n",
    "2. **Quản lý Database:**\n",
    "```python\n",
    "class DatabaseManager:\n",
    "    # Tạo table videos(id, url_video, transcription, criteria, created_at)\n",
    "    # Check URL tồn tại\n",
    "    # Insert dữ liệu mới\n",
    "```\n",
    "\n",
    "3. **Xử lý Audio:**\n",
    "```python\n",
    "class AudioProcessor:\n",
    "    # Process từng file audio qua API role_assign\n",
    "    # Combine transcriptions từ 2 file HV và mentor\n",
    "    # Analyze transcript để lấy criteria\n",
    "```\n",
    "\n",
    "4. **Main Processor:**\n",
    "```python\n",
    "class VideoProcessor:\n",
    "    # Bước 1: Tìm folders Audio và Video\n",
    "    # Bước 2: Lấy danh sách videos\n",
    "    # Bước 3: Với mỗi video:\n",
    "        # - Check URL đã tồn tại chưa\n",
    "        # - Tìm 2 file audio tương ứng (HV và mentor)\n",
    "        # - Download và process từng file audio\n",
    "        # - Combine transcriptions\n",
    "        # - Get criteria\n",
    "        # - Lưu vào database\n",
    "        # - Cleanup files tạm\n",
    "```\n",
    "\n",
    "**Cải tiến so với code cũ:**\n",
    "\n",
    "1. **Cấu trúc rõ ràng hơn:**\n",
    "- Tách thành các class riêng biệt\n",
    "- Mỗi class có nhiệm vụ cụ thể\n",
    "- Dễ maintain và debug\n",
    "\n",
    "2. **Error handling tốt hơn:**\n",
    "- Sử dụng logging thay vì print\n",
    "- Try-except chi tiết\n",
    "- Thông báo lỗi rõ ràng\n",
    "\n",
    "3. **Cleanup tốt hơn:**\n",
    "- Xóa files tạm sau khi xử lý\n",
    "- Không tạo nhiều thư mục con\n",
    "\n",
    "4. **Database tối ưu hơn:**\n",
    "- Thêm UNIQUE constraint cho URL\n",
    "- Thêm timestamp\n",
    "- Lưu cả transcript và criteria\n",
    "\n",
    "5. **Hiệu quả hơn:**\n",
    "- Check trùng lặp trước khi xử lý\n",
    "- Rate limiting để tránh lỗi API\n",
    "- Quản lý resources tốt hơn\n",
    "\n",
    "Bạn thấy cách tổ chức này thế nào?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Output hoàn chỉnh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, tôi sẽ giải thích chi tiết từng phần:\n",
    "\n",
    "**1. INPUT:**\n",
    "- Folder ID từ Google Drive (chứa 2 thư mục con: Audio và Video)\n",
    "```python\n",
    "folder_id = \"1_oVkhMaU4M1-ZIkb5sL4XSRE1LmZUn3z\"\n",
    "```\n",
    "\n",
    "Cấu trúc folder:\n",
    "```\n",
    "Main Folder/\n",
    "├── Audio/\n",
    "│   ├── video1_HV.wav      # Audio của học viên\n",
    "│   └── video1_mentor.wav  # Audio của mentor\n",
    "└── Video/\n",
    "    └── video1.mp4         # File video gốc\n",
    "```\n",
    "\n",
    "**2. TẠO TRANSCRIPTION:**\n",
    "```python\n",
    "def process_audio(self, audio_path: str, language: str = 'en'):\n",
    "    # 1. Gửi audio file đến transcribe API\n",
    "    response = requests.post(\n",
    "        'http://103.253.20.13:25029/role_assign',\n",
    "        files={'audio': audio_file},\n",
    "        data={\n",
    "            'secret_key': 'codedongian',\n",
    "            'language': language\n",
    "        }\n",
    "    )\n",
    "```\n",
    "\n",
    "Sau đó combine 2 transcripts:\n",
    "```python\n",
    "def combine_transcriptions(self, hv_output: Dict, mentor_output: Dict):\n",
    "    # 1. Extract text từ output\n",
    "    hv_data = self.extract_dicts(hv_output['output'])\n",
    "    mentor_data = self.extract_dicts(mentor_output['output'])\n",
    "\n",
    "    # 2. Đánh dấu speaker\n",
    "    for item in hv_data:\n",
    "        item['speaker'] = '1'\n",
    "    for item in mentor_data:\n",
    "        item['speaker'] = '2'\n",
    "\n",
    "    # 3. Sort theo thời gian và format\n",
    "    combined = sorted(hv_data + mentor_data, key=lambda x: x['start_time'])\n",
    "    formatted = [\n",
    "        f\"[{self.format_time(item['start_time'])}] Speaker {item['speaker']}: {item['text']}\"\n",
    "        for item in combined\n",
    "    ]\n",
    "\n",
    "    return \"\\n\".join(formatted)\n",
    "```\n",
    "\n",
    "**3. LẤY CRITERIA:**\n",
    "```python\n",
    "def analyze_transcript(self, transcript: str):\n",
    "    # Gửi transcript đến analyze API\n",
    "    response = requests.post(\n",
    "        'http://103.253.20.13:25034/analyze',\n",
    "        headers={'Content-Type': 'application/json'},\n",
    "        json={'transcription': transcript}\n",
    "    )\n",
    "    return response.json().get('criteria', '')\n",
    "```\n",
    "\n",
    "**4. OUTPUT:**\n",
    "Lưu vào database `videos` với các trường:\n",
    "```sql\n",
    "CREATE TABLE videos (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    url_video TEXT NOT NULL UNIQUE,  -- URL video từ Google Drive\n",
    "    transcription TEXT,              -- Transcription đã combine\n",
    "    criteria TEXT,                   -- Kết quả phân tích\n",
    "    created_at TIMESTAMP            -- Thời điểm xử lý\n",
    ")\n",
    "```\n",
    "\n",
    "**Ví dụ một record hoàn chỉnh:**\n",
    "```python\n",
    "{\n",
    "    'id': 1,\n",
    "    'url_video': 'https://drive.google.com/file/d/123abc/view',\n",
    "    'transcription': \"\"\"\n",
    "        [00:00:15] Speaker 1: Hello, how are you?\n",
    "        [00:00:18] Speaker 2: I'm fine, thank you.\n",
    "        ...\n",
    "    \"\"\",\n",
    "    'criteria': '<Kết quả phân tích từ API>',\n",
    "    'created_at': '2024-11-05 10:30:00'\n",
    "}\n",
    "```\n",
    "\n",
    "**Quy trình tổng thể:**\n",
    "1. Từ video trong folder Video, tìm 2 file audio tương ứng trong folder Audio\n",
    "2. Process từng file audio qua API role_assign để lấy transcription\n",
    "3. Combine 2 transcription, sắp xếp theo thời gian\n",
    "4. Gửi transcript đã combine qua API analyze để lấy criteria\n",
    "5. Lưu URL video + transcript + criteria vào database\n",
    "\n",
    "Bạn cần làm rõ phần nào thêm không?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Update đường dẫn \n",
    "\n",
    "Quản lý đường dẫn tập trung:\n",
    "\n",
    "```python\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "```\n",
    "Mọi đường dẫn đều relative to BASE_DIR\n",
    "Dễ di chuyển/deploy code\n",
    "Tránh lỗi đường dẫn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. UPDATE LOGGING CHI TIẾT HƠN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log cho thấy chương trình đã thực hiện thành công các bước đầu tiên:\n",
    "\n",
    "1. **Database initialized:** \n",
    "```\n",
    "2024-11-05 20:57:49,800 - INFO - Database initialized\n",
    "```\n",
    "- Database đã được tạo/kết nối thành công\n",
    "\n",
    "2. **Looking for folders:**\n",
    "```\n",
    "2024-11-05 20:57:49,807 - INFO - Looking for Audio and Video folders in 1_oVkhMaU4M1-ZIkb5sL4XSRE1LmZUn3z\n",
    "```\n",
    "- Bắt đầu tìm kiếm trong folder gốc với ID: `1_oVkhMaU4M1-ZIkb5sL4XSRE1LmZUn3z`\n",
    "\n",
    "3. **Found both folders:**\n",
    "```\n",
    "2024-11-05 20:57:50,708 - INFO - Found Audio folder: 1toZNe0bWvgXK5AXjm9uJnL8iDSkcmJjl\n",
    "2024-11-05 20:57:50,709 - INFO - Found Video folder: 12OTFQ6EHWnfJtfFa8gNaaMzinxsz8eRP\n",
    "```\n",
    "- Tìm thấy cả 2 folder Audio và Video\n",
    "- Mỗi folder có ID riêng để xử lý tiếp\n",
    "\n",
    "Thêm logging chi tiết hơn để theo dõi các bước tiếp theo:\n",
    "\n",
    "```python\n",
    "def process_folder(self, folder_id: str):\n",
    "    try:\n",
    "        # Find folders\n",
    "        audio_folder, video_folder = self.find_folders(folder_id)\n",
    "        if not audio_folder or not video_folder:\n",
    "            self.logger.error(\"Could not find both Audio and Video folders\")\n",
    "            return\n",
    "\n",
    "        # Get list of videos\n",
    "        self.logger.info(f\"Getting videos from folder: {video_folder}\")\n",
    "        videos = self.drive_service.files().list(\n",
    "            q=f\"'{video_folder}' in parents\",\n",
    "            fields=\"files(id, name)\"\n",
    "        ).execute().get('files', [])\n",
    "        self.logger.info(f\"Found {len(videos)} videos\")\n",
    "\n",
    "        # Process each video\n",
    "        for video in videos:\n",
    "            self.logger.info(f\"\\nProcessing video: {video['name']}\")\n",
    "            video_url = f\"https://drive.google.com/file/d/{video['id']}/view\"\n",
    "            \n",
    "            # Check if already processed\n",
    "            if self.db.url_exists(video_url):\n",
    "                self.logger.info(f\"Skipping existing video: {video['name']}\")\n",
    "                continue\n",
    "\n",
    "            # Find corresponding audio files\n",
    "            self.logger.info(f\"Looking for audio files for video: {video['name']}\")\n",
    "            base_name = os.path.splitext(video['name'])[0]\n",
    "            audio_files = self.drive_service.files().list(\n",
    "                q=f\"'{audio_folder}' in parents and (name contains '{base_name}')\",\n",
    "                fields=\"files(id, name)\"\n",
    "            ).execute().get('files', [])\n",
    "            self.logger.info(f\"Found {len(audio_files)} related audio files\")\n",
    "\n",
    "            # Find HV and mentor files\n",
    "            hv_file = None\n",
    "            mentor_file = None\n",
    "            for file in audio_files:\n",
    "                self.logger.info(f\"Checking audio file: {file['name']}\")\n",
    "                if 'HV' in file['name']:\n",
    "                    hv_file = file\n",
    "                    self.logger.info(f\"Found HV file: {file['name']}\")\n",
    "                elif 'mentor' in file['name']:\n",
    "                    mentor_file = file\n",
    "                    self.logger.info(f\"Found mentor file: {file['name']}\")\n",
    "\n",
    "            if not (hv_file and mentor_file):\n",
    "                self.logger.error(f\"Missing audio files for video: {video['name']}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Download and process HV file\n",
    "                self.logger.info(f\"Processing HV file: {hv_file['name']}\")\n",
    "                hv_path = os.path.join(self.config.TEMP_DIR, f\"hv_{video['id']}.wav\")\n",
    "                self.logger.info(f\"Downloading HV file to: {hv_path}\")\n",
    "                gdown.download(f\"https://drive.google.com/uc?id={hv_file['id']}\", \n",
    "                             hv_path, quiet=False)\n",
    "                hv_result = self.audio_processor.process_audio(hv_path)\n",
    "\n",
    "                # Download and process mentor file\n",
    "                self.logger.info(f\"Processing mentor file: {mentor_file['name']}\")\n",
    "                mentor_path = os.path.join(self.config.TEMP_DIR, f\"mentor_{video['id']}.wav\")\n",
    "                self.logger.info(f\"Downloading mentor file to: {mentor_path}\")\n",
    "                gdown.download(f\"https://drive.google.com/uc?id={mentor_file['id']}\", \n",
    "                             mentor_path, quiet=False)\n",
    "                mentor_result = self.audio_processor.process_audio(mentor_path)\n",
    "\n",
    "                if hv_result and mentor_result:\n",
    "                    self.logger.info(\"Combining transcriptions...\")\n",
    "                    transcript = self.audio_processor.combine_transcriptions(\n",
    "                        hv_result, mentor_result)\n",
    "                    \n",
    "                    self.logger.info(\"Getting criteria...\")\n",
    "                    criteria = self.audio_processor.analyze_transcript(transcript)\n",
    "\n",
    "                    # Save to database\n",
    "                    self.logger.info(\"Saving to database...\")\n",
    "                    if self.db.insert_video(video_url, transcript, criteria):\n",
    "                        self.logger.info(f\"Successfully processed video: {video['name']}\")\n",
    "\n",
    "                # Cleanup\n",
    "                self.logger.info(\"Cleaning up temporary files...\")\n",
    "                for path in [hv_path, mentor_path]:\n",
    "                    if os.path.exists(path):\n",
    "                        os.remove(path)\n",
    "                        self.logger.info(f\"Removed temporary file: {path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error processing video {video['name']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            time.sleep(3)\n",
    "\n",
    "    except Exception as e:\n",
    "        self.logger.error(f\"Error in main processing: {str(e)}\")\n",
    "\n",
    "```\n",
    "\n",
    "Sau khi thêm logging chi tiết, bạn có thể theo dõi từng bước:\n",
    "1. Tìm folders ✓\n",
    "2. Lấy danh sách videos\n",
    "3. Với mỗi video:\n",
    "   - Tìm audio files\n",
    "   - Download và xử lý HV file\n",
    "   - Download và xử lý mentor file\n",
    "   - Combine transcriptions\n",
    "   - Get criteria\n",
    "   - Save to database\n",
    "   - Cleanup\n",
    "\n",
    "Bạn chạy lại code và cho mình biết các bước tiếp theo có lỗi gì không nhé!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. BUG LƯU DICT JSON VÀO DATABASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có 2 lỗi chính đang xảy ra:\n",
    "\n",
    "1. **Lỗi khi lưu vào database:**\n",
    "```\n",
    "ERROR - Database error: Error binding parameter 3: type 'dict' is not supported\n",
    "```\n",
    "Nguyên nhân: API analyze trả về một dictionary (dạng JSON), nhưng SQLite không thể lưu trực tiếp kiểu dữ liệu dictionary. \n",
    "\n",
    "```python\n",
    "# Response từ API có dạng:\n",
    "{\n",
    "    \"criteria\": {\n",
    "        \"3Ps\": {\n",
    "            \"recommendationScore\": {\n",
    "                \"reason\": \"<b>Present: 8/10</b> Nhận xét: Presentation of ideas was clear...\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "2. **Lỗi encoding tiếng Việt:**\n",
    "```\n",
    "UnicodeEncodeError: 'charmap' codec can't encode character '\\u1ead' in position 202\n",
    "```\n",
    "Nguyên nhân: Logger không thể xử lý các ký tự tiếng Việt với encoding mặc định.\n",
    "\n",
    "Cách sửa:\n",
    "\n",
    "```python\n",
    "# 1. Sửa logging để handle tiếng Việt\n",
    "def setup_logging(config: Config) -> logging.Logger:\n",
    "    \"\"\"Setup logging với UTF-8 encoding\"\"\"\n",
    "    os.makedirs(config.LOG_DIR, exist_ok=True)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    if not logger.handlers:\n",
    "        # File handler với encoding UTF-8\n",
    "        fh = logging.FileHandler(\n",
    "            os.path.join(config.LOG_DIR, 'app.log'),\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "        logger.addHandler(fh)\n",
    "        \n",
    "        # Console handler với encoding UTF-8\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "        logger.addHandler(ch)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# 2. Sửa hàm analyze_transcript để convert dictionary thành string\n",
    "def analyze_transcript(self, transcript: str) -> Optional[str]:\n",
    "    \"\"\"Analyze transcript và convert kết quả thành string\"\"\"\n",
    "    try:\n",
    "        self.logger.info(\"Preparing to analyze transcript...\")\n",
    "        \n",
    "        response = requests.post(\n",
    "            self.config.ANALYZE_API_URL,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            json={\"transcription\": transcript},\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            # Convert dictionary thành JSON string để lưu vào DB\n",
    "            criteria_str = json.dumps(result.get('criteria', {}), \n",
    "                                   ensure_ascii=False, \n",
    "                                   indent=2)\n",
    "            return criteria_str\n",
    "        else:\n",
    "            self.logger.error(f\"API error: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        self.logger.error(f\"Error analyzing transcript: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 3. Sửa Database để handle UTF-8\n",
    "class DatabaseManager:\n",
    "    def create_database(self):\n",
    "        \"\"\"Create database với UTF-8 encoding\"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            conn.execute('PRAGMA encoding = \"UTF-8\"')\n",
    "            conn.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS videos (\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    url_video TEXT NOT NULL UNIQUE,\n",
    "                    transcription TEXT,\n",
    "                    criteria TEXT,  -- Lưu JSON string\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            ''')\n",
    "            self.logger.info(\"Database initialized with UTF-8 encoding\")\n",
    "\n",
    "```\n",
    "\n",
    "Những thay đổi chính:\n",
    "\n",
    "1. **Xử lý tiếng Việt:**\n",
    "- Thêm UTF-8 encoding cho logging\n",
    "- Set PRAGMA encoding = \"UTF-8\" cho SQLite\n",
    "- Dùng `ensure_ascii=False` khi convert JSON\n",
    "\n",
    "2. **Xử lý dữ liệu criteria:**\n",
    "- Convert dictionary thành JSON string trước khi lưu\n",
    "- Khi đọc lại, có thể parse string thành dictionary:\n",
    "```python\n",
    "criteria_dict = json.loads(row['criteria'])\n",
    "```\n",
    "\n",
    "3. **Cách đọc criteria từ DB:**\n",
    "```python\n",
    "def get_video_details(self, video_id: int):\n",
    "    with self.get_connection() as conn:\n",
    "        cursor = conn.execute('''\n",
    "            SELECT id, url_video, transcription, criteria\n",
    "            FROM videos WHERE id = ?\n",
    "        ''', (video_id,))\n",
    "        row = cursor.fetchone()\n",
    "        if row:\n",
    "            # Parse criteria string back to dictionary\n",
    "            criteria = json.loads(row[3]) if row[3] else {}\n",
    "            return {\n",
    "                'id': row[0],\n",
    "                'url': row[1],\n",
    "                'transcription': row[2],\n",
    "                'criteria': criteria\n",
    "            }\n",
    "        return None\n",
    "```\n",
    "\n",
    "Bạn thử chạy lại với những thay đổi này xem còn lỗi không nhé!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
